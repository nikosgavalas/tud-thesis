%!TEX root = ../main.tex

\chapter{Introduction}

\label{Chapter1}

Cloud Computing has seen a dramatic rise in its adoption the recent years, with an increasing number of enterprises migrating their software and hardware to the cloud, and this trend is only expected to continue [\cite{serverless-preds}].
Historically, this shift towards managed infrastructure has been arguably inevitable, because with cloud computing the cost per unit of computation is minimized [\cite{rise-of-serverless}].
The drive for increased efficiency in computation has culminated in the emergence of the \textit{serverless} architecture [\cite{serverless-definition}].

In the serverless cloud computing execution model, applications are being developed as collections of fine-grained event-driven and stateless units of computation called \textit{cloud functions}.
Cloud providers offer the execution of serverless functions as a paid service, known as \textit{Function-as-a-Service} or \textit{FaaS} [\cite{faas-definition}].

While FaaS offerings prioritize scalability by being stateless, most applications require some form of state management, resulting in developers resorting to external databases for their applications' state-keeping.
Several recent works have aimed to alleviate the burden of state management from application developers [\cite{orleans,durable-functions,beldi}] by enabling the transparent management of application state through external databases, thereby providing \textit{stateful functions}, or \textit{SFaaS}.

SFaaS systems ease the development of stateful applications, but they are not a panacea per se.
Any programmer that develops distributed applications will eventually have to deal with fundamental potential issues such as network partitioning, system failures, and the Byzantine generals messaging problem [\cite{byzantine}].
These problems become especially hard to deal with when the application level requires implementing \textit{transactional} logic, as transactions require extra guarantees. Transactions are sets of operations that must adhere to the ACID principles - Atomicity, Consistency, Isolation, and Durability [\cite{transaction-definition}]. 

Consequently, developers often find themselves intermixing business logic with consistency checks, rollbacks, snapshots, and timeouts, resulting in systems that are highly intricate to maintain and prone to failures. This highlights the need for an intermediary layer that abstracts the distributed fault tolerance logic and provides application developers with specific guarantees, both at the state-management level and the transactional level, if feasible.

SFaaS systems built on top of \textit{stateful streaming dataflow engines} such as Apache Flink StateFun [\cite{apache-flink}] make excellent candidates for implementing \textit{transactional SFaaS} systems, primarily for two reasons [\cite{transactions-serverless-functions-leveraging-stateful-dataflows}]:

\begin{enumerate}
    \item They offer \textit{exactly-once} message delivery semantics, eliminating the need for identifying lost messages and resending them, and also guarantee the message delivery order - the communication channels between the distributed components are FIFO.

    \item They fully manage the system's global distributed state by periodically creating consistent snapshots and recovering them upon failures. This is especially important for implementing transactions, since for failed transactions there needs to be a rollback mechanism to guarantee the Atomicity property.
\end{enumerate}

Dataflow SFaaS systems are comprised of multiple worker processes, with each of them keeping a partition of the global state locally [\cite{apache-flink}]. The state is represented as key-value pairs, making key-value stores an ideal choice as embedded databases for this task.

As the key-value store is a critical component of this architecture, it is essential to carefully evaluate the available options of suitable types of key-value stores and motivate our selection. Towards this end, in this study, we implement three different kinds of key-value stores, evaluate their performance within transactional dataflow systems and conduct a comprehensive comparative analysis among them.

\section{Design Requirements}
\label{design-requirements}

In a (transactional) dataflow SFaaS system, the key-value stores need to have specific properties to be considered suitable. These properties, extending those mentioned in the work of \cite{faster}, are:

\begin{enumerate}
    \item \textit{Incremental snapshots} [\cite{state-management-apache-flink}].
    When the dataflow engine requests a worker to create a snapshot of its state, the state backend (the key-value store) will dump the state and save it. As this process happens many times during the execution of a workflow, to ensure fault tolerance and fast state recovery, it is imperative that it is done efficiently, building on previous snapshots.
    
    The naive solution is to save the whole state every time, but if there is a way to only save the updates on the state at each step, incrementally, it would definitely be more efficient. However, saving only the updates on each step would make recovery very slow, as the state would need to be rebuilt from the very beginning in case of a system failure.
    In this work, we propose a solution that combines \textit{fast incremental snapshots with low recovery times}.

    \item \textit{State recovery to a previous version from previous snapshots (rollback)} [\cite{snapshots-rollbacks,state-management-apache-flink}]. Upon execution, the dataflow coordinator process may request the workers to restore some previous version of their state, so that the system can go back to some consistent global state and ``replay'' events to recover from some failure.
    
    \item \textit{Larger-than-memory data (spill-to-disk)}.
    When dealing with large volumes of data, it is expected that during execution the state will exceed in size the amount that can be stored in memory.
    Hence, it is essential that the key-value store employs persistent storage when necessary to handle states larger than the available memory.

    \item \textit{Update intensity}.
    In dataflow systems, changes to the state are typically characterized by the volume of updates rather than inserts or deletes.
    This is particularly evident in workflows that involve data aggregations or analytics, and it holds even more significance in systems that support transactions.
    Transactional systems often involve frequent operations like value increments. As a result, the state backend needs to be well-suited for update-heavy workloads.

    \item \textit{Locality}.
    In real-world dataflow applications, access to data is rarely uniformly distributed.
    Keys that are ``alive'' at any moment may be of many orders of magnitude, but it's usually a subset of those that are ``hot'' at some given time, i.e. accessed or updated frequently.
    The hot set may drift as time passes but the strong temporal locality property is maintained.

    \item \textit{Point operations}.
    A key-value store for our use case should be optimal for point operations, i.e. operations associated with a single key, as opposed to range operations.
    Since state updates rarely operate on ranges of keys, we can leverage this knowledge to our advantage.
\end{enumerate}

\section{Research Questions}
\label{section-reseach-questions}

At this juncture we can outline the main research questions of this work. The first research question is:\\

\begin{tcolorbox}
    \textbf{RQ1}: Which type or types of key-value stores are more fitting as embedded state stores in the worker processes of transactional dataflow SFaaS systems?
\end{tcolorbox}

\vspace{8px}
To address this question in alignment with the design requirements outlined in subsection \ref{design-requirements}, our approach involves several steps.
Firstly, we will survey and examine existing key-value store designs, considering their suitability for our purposes.
Next, we will carefully narrow down our options and provide a compelling rationale for our chosen selections.
Subsequently, we will proceed to implement the most promising candidates, and study them in depth, which leads us to the second and third research questions:\\

\begin{tcolorbox}
    \textbf{RQ2}: How do changes in the parameters of each selected type of key-value store affect its performance?
\end{tcolorbox}
\vspace{8px}

\begin{tcolorbox}
    \textbf{RQ3}: In the selected types of key-value stores, which are the trade-offs that determine their operation? In which general use cases does each of them perform better?
\end{tcolorbox}
\vspace{8px}

Next, we will proceed with a thorough evaluation of the implemented key-value stores by integrating them into a transactional dataflow system. During this evaluation, we will specifically focus on assessing the efficiency of the incremental snapshotting functionality and its impact. Thus, our fourth research question is formulated as follows:\\

\begin{tcolorbox}
    \textbf{RQ4}: How does the performance of a key-value store that incorporates incremental snapshotting functionality compare to that of a "naive" in-memory key-value store, which captures snapshots of its entire state at each step, in terms of snapshot creation time?
\end{tcolorbox}
\vspace{8px}

Ultimately, we will be able to address the final research question:\\

\begin{tcolorbox}
    \textbf{RQ5}: Is there a key-value store that clearly stands out as the superior choice for state management?
    % TODO spoiler alert no, offer the programmer the ability to choose based on his app's reqs
\end{tcolorbox}
\vspace{8px}

\section{Contributions}

We summarize this work's contributions in the following points:

\begin{enumerate}
    \item \textit{Design and implementation of Three Key-Value Stores}: To ensure a fair comparison and level playing field, we have implemented three distinct key-value store implementations. Each implementation adheres to the same programming language and incorporates similar design choices for shared functionality, such as data encoding and data structures. By keeping these aspects consistent, we can isolate the differences in the key-value store logic and facilitate accurate comparisons.
    
    \item \textit{Experimental Analysis}: In order to address the research questions outlined in section \ref{section-reseach-questions}, we have conducted a series of experiments. These experiments focus on analyzing the parameters of each implemented key-value store and exploring the trade-offs inherent in their designs, particularly in terms of resource utilization. By systematically examining these aspects, we aim to gain a deeper understanding of the strengths and weaknesses of each key-value store implementation.

    \item \textit{Comprehensive Comparison}: Building upon the experimental analysis, we have conducted a comprehensive comparison among the implemented key-value. This comparison encompasses various factors, including the effectiveness of incremental snapshotting, which plays a vital role in state management. Ultimately, our goal is to determine whether one key-value store emerges as the optimal choice for our specific use case. By thoroughly evaluating the performance and capabilities of each implementation, we aim to provide insights and make informed recommendations for state management in transactional dataflow systems.
\end{enumerate}

\section{Outline}

The rest of the thesis is structured as follows:

Chapter \ref{Chapter2-related-work} provides a review of the existing literature and related work in the field. It explores previous research, methodologies, and advancements in key-value stores and state management within transactional dataflow systems. This chapter establishes a solid foundation for our study.

In Chapter \ref{Chapter3-implementation} we delve into comprehensive descriptions of the internal workings of each type of key-value store. We provide in-depth insights into their underlying mechanisms, data structures, and algorithms. Furthermore, we discuss the specific implementation details and design decisions that pertain to each key-value store type. By thoroughly understanding the intricacies of each implementation, we lay the groundwork for subsequent evaluations and comparisons.

Chapter \ref{Chapter4-evaluation} is dedicated to the evaluation of our implemented key-value stores. We conduct a series of benchmarks and comparisons to assess their performance and capabilities. This includes integrating the key-value stores into a transactional dataflow system to simulate real-world usage scenarios. By rigorously evaluating their performance, scalability, and efficiency, we gain valuable insights into the strengths and limitations of each implementation. We discuss the obtained results and analyze the implications they have on state management in transactional dataflow systems.

In the final chapter, \ref{Chapter5-conclusion}, we provide a comprehensive summary of our research and findings. We present our conclusions based on the evaluation and comparisons performed. We also address the research questions posed earlier in the thesis and provide insightful answers. Additionally, we discuss potential directions for future research and highlight areas that require further exploration and development.
% TODO and mention the limitations of this work?
